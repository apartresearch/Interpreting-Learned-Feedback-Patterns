{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0013fe-1e8c-463a-a0c9-dcf828e8d858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pprint\n",
    "import random\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from dataclasses import dataclass\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "from matplotlib import pyplot\n",
    "from scipy.sparse import csr_matrix, vstack\n",
    "from scipy.stats import kendalltau\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from torch import Tensor\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cc0499-e309-4274-9083-7971ddef23d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "sentiment_analyzer = SentimentIntensityAnalyzer()\n",
    "lexicon = sentiment_analyzer.lexicon\n",
    "\n",
    "min_vader_value = min(lexicon.values())\n",
    "max_vader_value = max(lexicon.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdf6b59-1d37-48f1-b374-840c38ea254b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'linear_probe_training_dataset'\n",
    "policy_model_name = 'gpt_neo_125m_utility_reward'\n",
    "project_name = 'utility_reconstruction'\n",
    "version = 'v1'\n",
    "random_seed = 42\n",
    "\n",
    "os.environ['WANDB_API_KEY'] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee2fc8c-70b0-4c0e-ad42-13606a477ddb",
   "metadata": {},
   "source": [
    "### Randomization and other utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b1f21c-46e7-42bc-ae93-6a09bb1895b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clamp(number, min_value, max_value):\n",
    "    return max(min(number, max_value), min_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b19642c-bdec-4756-806b-d060f2299ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_values(list_of_dicts):\n",
    "    # Use defaultdict to simplify code\n",
    "    token_sum = defaultdict(float)\n",
    "    token_count = defaultdict(int)\n",
    "\n",
    "    # Accumulate sums and counts\n",
    "    for d in list_of_dicts:\n",
    "        for token, value in d.items():\n",
    "            token_sum[token] += value\n",
    "            token_count[token] += 1\n",
    "\n",
    "    # Calculate average values using a dictionary comprehension\n",
    "    average_values = {token: round(token_sum[token] / token_count[token], 3) for token in token_sum}\n",
    "\n",
    "    return average_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decbfacd-2831-4672-b02c-6829a7c44a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_value(value, values_list, new_min=min_vader_value, new_max=max_vader_value):\n",
    "    percentile_range = 90\n",
    "\n",
    "    old_max = np.percentile(values_list, percentile_range)\n",
    "    old_min = np.percentile(values_list, 100 - percentile_range)\n",
    "    \n",
    "    # First, normalize the value to a range between 0 and 1\n",
    "    normalized_value = (value - old_min) / (old_max - old_min)\n",
    "    \n",
    "    # Then, scale the normalized value to the new range\n",
    "    new_value = normalized_value * (new_max - new_min) + new_min\n",
    "\n",
    "    new_value = clamp(new_value, new_min, new_max)\n",
    "    \n",
    "    return round(new_value, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e67890f-786f-49b6-a141-b229052f795c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_split_list(lst, split_ratio=0.8, seed=random_seed):\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "    \n",
    "    shuffled_list = lst[:]\n",
    "    random.shuffle(shuffled_list)\n",
    "    \n",
    "    split_index = int(len(shuffled_list) * split_ratio)\n",
    "    return shuffled_list[:split_index], shuffled_list[split_index:]\n",
    "\n",
    "random_split_list([1,2,3,4,5,6,7,8,9,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdedb5d-0f1d-41f6-893f-fb7bf972ba7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concantenate_matrices(layer_to_csr_dict):\n",
    "    \"\"\"\n",
    "    Given a dictionary of layername_to_features matrices, this flattens and concatenates\n",
    "    the matrices, in canoncial sorted order of the dictionary keys (the layernames).\n",
    "    \"\"\"\n",
    "    sorted_matrices = [\n",
    "        layer_to_csr_dict[key] for key in sorted(layer_to_csr_dict.keys())\n",
    "    ]\n",
    "    concatenated_matrix = vstack(sorted_matrices)\n",
    "    return concatenated_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8deb1a-299a-4852-974b-7be3315a8154",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(matrix1: csr_matrix, matrix2: csr_matrix):\n",
    "    # Convert CSR matrices to dense arrays for cdist\n",
    "    dense_matrix1 = matrix1.toarray().flatten()\n",
    "    dense_matrix2 = matrix2.toarray().flatten()\n",
    "\n",
    "    # Compute Euclidean distance using cdist\n",
    "    distance = np.linalg.norm(dense_matrix1 - dense_matrix2)\n",
    "\n",
    "    return distance\n",
    "\n",
    "def euclidean_distance_bw_dicts_of_csr_matrices(\n",
    "    matrix_dict_1: dict[str, csr_matrix], matrix_dict_2: dict[str, csr_matrix]):\n",
    "\n",
    "    feature_matrix_1 = concantenate_matrices(matrix_dict_1)\n",
    "    feature_matrix_2 = concantenate_matrices(matrix_dict_2)\n",
    "\n",
    "    return euclidean_distance(feature_matrix_1, feature_matrix_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec088ec-f34c-41a8-a008-bc8d9526d6ce",
   "metadata": {},
   "source": [
    "### Load artifact from wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b19e4f-9fd9-4886-aace-0573ad036fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(project=f'{project_name}_{policy_model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12e0f28-1948-4248-800a-ebe5d4acc53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.run.config['random_seed'] = random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c58ec0f-d247-4ae6-beb9-10bcd55ca416",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_linear_probe_training_dataset(policy_model_name=policy_model_name, project_name=project_name, version=version):\n",
    "    artifact_path = f'linear_probe_training_dataset_{policy_model_name}:{version}'\n",
    "    \n",
    "    artifact = run.use_artifact(\n",
    "        f'nlp_and_interpretability/{project_name}/{artifact_path}', type='data'\n",
    "    )\n",
    "    artifact_dir = artifact.download()\n",
    "\n",
    "    with open(f'artifacts/{artifact_path}/{filename}', 'rb') as f_in:\n",
    "        training_dataset = pickle.load(f_in)\n",
    "\n",
    "    return training_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3702f8b9-fda0-4857-ba97-31549bbfe4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TextTokensIdsTarget:\n",
    "    attention_mask: list[int]\n",
    "    text: str\n",
    "    tokens: list[str]\n",
    "    ids: list[int]\n",
    "    target_token: str\n",
    "    target_token_id: int\n",
    "    target_token_position: int\n",
    "\n",
    "    @staticmethod\n",
    "    def get_tensorized(datapoints: \"TextTokensIdsTarget\"):\n",
    "        max_length = max([len(datapoint.tokens) for datapoint in datapoints])\n",
    "        \n",
    "        input_ids = [datapoint.ids for datapoint in datapoints]\n",
    "        attention_masks = [datapoint.attention_mask for datapoint in datapoints]\n",
    "\n",
    "        input_ids_padded = pad_list_of_lists(input_ids, tokenizer.encode(tokenizer.pad_token)[0])\n",
    "        attention_masks_padded = pad_list_of_lists(attention_masks, 0)\n",
    "        all_tokenized = {\n",
    "            \"input_ids\": torch.IntTensor(input_ids_padded).cuda(), \"attention_mask\": torch.ByteTensor(attention_masks_padded).cuda()\n",
    "        }\n",
    "        return all_tokenized\n",
    "\n",
    "\n",
    "\n",
    "### Source training point in the wandb artifact\n",
    "class TrainingPoint:\n",
    "\n",
    "    def __init__(self, input_dict: dict, tokenizer=None):\n",
    "        self.input_dict = input_dict\n",
    "        self.positive_text = input_dict['input_text']\n",
    "        self.negative_text = input_dict['output_text']\n",
    "        self.neutral_text = input_dict['neutral_text']\n",
    "        \n",
    "        # Dictionary of layer name to activations by mlp layer.\n",
    "        self.activations: dict = None\n",
    "\n",
    "        # Dictionary of layer name to autoencoder feature by mlp layer\n",
    "        self.autoencoder_feature: dict = None\n",
    "\n",
    "        # Reward value of target_token.\n",
    "        self.target_positive_reward = None\n",
    "        self.target_negative_reward = None\n",
    "\n",
    "        self.positive_text_tokens, self.positive_input_ids = get_tokens_and_ids(self.positive_text)\n",
    "        self.negative_text_tokens, self.negative_token_ids = get_tokens_and_ids(self.negative_text)\n",
    "        \n",
    "        self.positive_words = input_dict['positive_words']\n",
    "        self.negative_words = list(input_dict['new_words'].values())\n",
    "        self.neutral_words = list(input_dict['neutral_words'].values())\n",
    "\n",
    "        self.target_positive_reward = None\n",
    "        self.target_positive_token = None\n",
    "        self.target_positive_token_id = None\n",
    "    \n",
    "        self.target_negative_reward = None\n",
    "        self.target_negative_token = None\n",
    "        self.target_negative_token_id = None\n",
    "\n",
    "        self.target_neutral_token = None\n",
    "        self.target_neutral_token_id = None\n",
    "\n",
    "        try:\n",
    "            self.trimmed_positive_example: \"TextTokensIdTarget\" = trim_example(self.positive_text, self.positive_words)\n",
    "            if self.trimmed_positive_example:\n",
    "                positive_token = self.trimmed_positive_example.target_token.strip().lower()\n",
    "                self.target_positive_reward = lexicon.get(positive_token, None)\n",
    "                self.target_positive_token = positive_token\n",
    "                self.target_positive_token_id = self.trimmed_positive_example.target_token_id\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f'Caught exception {e} on {input_dict} for positive example.')\n",
    "            self.trimmed_positive_example = None\n",
    "        \n",
    "        try:\n",
    "            self.trimmed_negative_example: \"TextTokensIdTarget\" = trim_example(self.negative_text, self.negative_words)\n",
    "            if self.trimmed_negative_example:\n",
    "                negative_token = self.trimmed_negative_example.target_token.strip().lower()\n",
    "                self.target_negative_reward = lexicon.get(negative_token, None)\n",
    "                self.target_negative_token = negative_token\n",
    "                self.target_negative_token_id = self.trimmed_negative_example.target_token_id\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f'Caught exception {e} on {input_dict} for negative example.')\n",
    "            self.trimmed_negative_example = None\n",
    "\n",
    "        try:\n",
    "            self.trimmed_neutral_example: \"TextTokensIdTarget\" = trim_example(self.neutral_text, self.neutral_words)\n",
    "            if self.trimmed_neutral_example:\n",
    "                self.target_neutral_token = self.trimmed_neutral_example.target_token.strip().lower()\n",
    "                self.target_neutral_token_id = self.trimmed_neutral_example.target_token_id\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f'Caught exception {e} on {input_dict} for neutral example.')\n",
    "            self.trimmed_neutral_example = None\n",
    "\n",
    "    def __str__(self):\n",
    "        return pprint.pformat(self.__dict__)\n",
    "\n",
    "\n",
    "class LinearProbeTrainingPoint:\n",
    "    def __init__(\n",
    "        self, training_point: \"TrainingPoint\",\n",
    "        # positive token\n",
    "        target_positive_token_id: int,\n",
    "        target_positive_token: str,\n",
    "        positive_token_ae_features: [str, Tensor], \n",
    "        # negative token\n",
    "        target_negative_token_id: int,\n",
    "        target_negative_token: str,\n",
    "        negative_token_ae_features: [str, Tensor],\n",
    "        # neutral token\n",
    "        target_neutral_token_id: int,\n",
    "        target_neutral_token: str,\n",
    "        neutral_token_ae_features: [str, Tensor]\n",
    "    ):\n",
    "        self.training_point: \"TrainingPoint\" = training_point\n",
    "\n",
    "        self.target_positive_token = target_positive_token\n",
    "        self.target_positive_token_id = target_positive_token_id\n",
    "        self.target_positive_reward = self.training_point.target_positive_reward\n",
    "        self.positive_token_ae_features = positive_token_ae_features\n",
    "\n",
    "        self.target_negative_token = target_negative_token\n",
    "        self.target_negative_token_id = target_negative_token_id\n",
    "        self.target_negative_reward = self.training_point.target_negative_reward\n",
    "        self.negative_token_ae_features = negative_token_ae_features\n",
    "\n",
    "        self.target_neutral_token = target_neutral_token\n",
    "        self.target_neutral_token_id = target_neutral_token_id\n",
    "        self.neutral_token_ae_features = neutral_token_ae_features\n",
    "\n",
    "    def __str__(self):\n",
    "        return pprint.pformat(self.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba321f7-398e-4861-9378-17c1901f16ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_training_dataset = load_linear_probe_training_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bfafb8-67ad-4985-90e6-31fe9ec2c513",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split_dataset, test_split_dataset = random_split_list(full_training_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0a98c8-6453-431b-ad59-992584ffb118",
   "metadata": {},
   "source": [
    "### Define linear probe helper classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d14ff89-3dbc-4120-97ce-6a92061c03ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class LinearProbeFinalInput:\n",
    "    token: str\n",
    "    token_id: int\n",
    "    divergence: float     # Divergence of the token to neutral token\n",
    "    features: csr_matrix  # Corresponds to the features of positive or negative token\n",
    "    point_type: str    # Can be positive or negative\n",
    "\n",
    "    def __str__(self):\n",
    "        return pprint.pformat(self.__dict__)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5f5a31-26cf-4976-b800-fe0ab12eabff",
   "metadata": {},
   "source": [
    "### Construct training dataset and linear probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d9a73e-a0e0-43ec-b122-0ce6429f24f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_lp_training_point_to_pair_of_lp_final_inputs(lp_training_point: LinearProbeTrainingPoint) -> list[LinearProbeFinalInput]:\n",
    "    positive_features = concantenate_matrices(\n",
    "        lp_training_point.positive_token_ae_features)\n",
    "\n",
    "    negative_features = concantenate_matrices(\n",
    "        lp_training_point.negative_token_ae_features)\n",
    "\n",
    "    neutral_features = concantenate_matrices(\n",
    "        lp_training_point.neutral_token_ae_features)\n",
    "\n",
    "    positive_token = lp_training_point.target_positive_token\n",
    "    positive_token_id = lp_training_point.target_positive_token_id\n",
    "    positive_divergence = euclidean_distance(\n",
    "        positive_features, neutral_features\n",
    "    )\n",
    "\n",
    "    # Positive input training example.\n",
    "    positive_probe_final_input = LinearProbeFinalInput(\n",
    "        token=positive_token, token_id=positive_token_id,\n",
    "        divergence=positive_divergence, features=positive_features,\n",
    "        point_type='positive'\n",
    "    )\n",
    "\n",
    "    negative_token = lp_training_point.target_negative_token\n",
    "    negative_token_id = lp_training_point.target_negative_token_id\n",
    "    negative_divergence = euclidean_distance(\n",
    "        negative_features, neutral_features\n",
    "    )\n",
    "\n",
    "    # Negative input training example - multiply divergence by minus one.\n",
    "    negative_probe_final_input = LinearProbeFinalInput(\n",
    "        token=negative_token, token_id=negative_token_id,\n",
    "        divergence=-1*negative_divergence, features=negative_features,\n",
    "        point_type='negative'\n",
    "    )\n",
    "\n",
    "    return [positive_probe_final_input, negative_probe_final_input]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe9a6e0-aa9e-419f-85e8-a654f66a205f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_point = train_split_dataset[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf7c647-5493-4c6c-8676-988dad5e7c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_test_point, negative_test_point = map_lp_training_point_to_pair_of_lp_final_inputs(test_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99107626-892e-45aa-9207-95160b1e988d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'\\nPositive point:\\n{pprint.pformat(positive_test_point)}')\n",
    "print(f'\\nNegative point:\\n{pprint.pformat(negative_test_point)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d1c9ef-42dc-44c1-9353-bc75c7b8cba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_lp_dataset_to_final_input_dataset(\n",
    "    input_dataset: list[LinearProbeTrainingPoint]) -> list[LinearProbeFinalInput]:\n",
    "\n",
    "    final_dataset = []\n",
    "\n",
    "    for datapoint in tqdm_notebook(input_dataset):\n",
    "        positive_point, negative_point = map_lp_training_point_to_pair_of_lp_final_inputs(datapoint)\n",
    "        final_dataset.append(positive_point)\n",
    "        final_dataset.append(negative_point)\n",
    "\n",
    "    return final_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea55e8a-3c01-4e1d-965b-6a28da79d813",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_train_split_dataset: list[LinearProbeFinalInput] = map_lp_dataset_to_final_input_dataset(\n",
    "    input_dataset = train_split_dataset\n",
    ")\n",
    "\n",
    "mapped_test_split_dataset: list[LinearProbeFinalInput] = map_lp_dataset_to_final_input_dataset(\n",
    "    input_dataset = test_split_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae3b9d7-c635-4f37-a6e2-40ff2ab02cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureConstructor:\n",
    "\n",
    "    def construct_feature_representation(self, linear_probe_inputs):\n",
    "        feature_rep = np.array([point.features.toarray().flatten() for point in linear_probe_inputs])\n",
    "        return feature_rep\n",
    "\n",
    "feature_constructor = FeatureConstructor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c574c5f-d26d-4f78-9ce2-95440a035f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_linear_model(train_linear_probe_inputs: list[LinearProbeFinalInput], feature_constructor: FeatureConstructor = feature_constructor):\n",
    "    input_points = feature_constructor.construct_feature_representation(train_linear_probe_inputs)\n",
    "\n",
    "    output_points = np.array([point.divergence for point in train_linear_probe_inputs])\n",
    "\n",
    "    print(f'Shapes are {input_points.shape} and {output_points.shape}')\n",
    "\n",
    "    model = Ridge()\n",
    "    wandb.run.summary['linear_model_type'] = 'Ridge'\n",
    "    model.fit(input_points, output_points)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f77205-df75-4cbf-9aee-70e596f9c98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = train_linear_model(train_linear_probe_inputs=mapped_train_split_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121272b9-3d72-4b07-9313-48c8bc77d6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fitted_values(linear_model, test_linear_probe_inputs, feature_constructor: FeatureConstructor = feature_constructor):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    test_inputs = feature_constructor.construct_feature_representation(test_linear_probe_inputs)\n",
    "    test_values = linear_model.predict(test_inputs)\n",
    "    return test_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d852ec-1308-4f79-99f9-cded3cfe6ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_values = get_fitted_values(linear_model=linear_model, test_linear_probe_inputs=mapped_test_split_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56b1855-ae3a-4a49-8bbd-7ba08b6deea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_values_and_inputs = list(zip(fitted_values, mapped_test_split_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b471793-7c97-476f-a77d-f69a0cf50834",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_values_and_inputs[15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8c8fd5-95c6-4ea0-82a3-bc8924874dcb",
   "metadata": {},
   "source": [
    "### Do analysis on divergence values viz-a-viz original Vader lexicon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798a8021-45b3-4b75-b036-27a4c19105f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fitted_values_and_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f405dcd8-5c7f-4173-9797-e0f797aaf3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_values_and_input_list_to_range(values_and_input_list, min_range=min_vader_value, max_range=max_vader_value):\n",
    "    all_probe_values = []\n",
    "    all_tokens = []\n",
    "    final_outputs = []\n",
    "    for values_and_inputs in values_and_input_list:\n",
    "        fitted_value = values_and_inputs[0]\n",
    "        token = values_and_inputs[1].token\n",
    "\n",
    "        all_probe_values.append(fitted_value)\n",
    "        all_tokens.append(token)\n",
    "\n",
    "    rescaled_values_and_input_list = [{input.token: rescale_value(value, all_probe_values)} for value, input in values_and_input_list]\n",
    "\n",
    "    return rescaled_values_and_input_list, all_tokens, all_probe_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f399ba6e-3a0e-4294-ac2d-58c4dea3961d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rescaled_values_and_input_list, all_test_tokens, all_probe_values = scale_values_and_input_list_to_range(\n",
    "    values_and_input_list=fitted_values_and_inputs\n",
    ")\n",
    "\n",
    "averaged_token_values = calculate_average_values(rescaled_values_and_input_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afa77e0-ac76-49bd-91c6-1cbec12147d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_positive_test_tokens = [token for token in all_test_tokens if lexicon.get(token, 0) > 0]\n",
    "all_negative_test_tokens = [token for token in all_test_tokens if lexicon.get(token, 0) < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e67e7a8-f009-4f14-bd52-d9d9fa0f00ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "rescaled_values_and_input_list = sorted(\n",
    "    rescaled_values_and_input_list, key=lambda x: list(x.keys())[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008baeeb-a857-4a63-bdbe-b4a4e7b1c669",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(random_seed)\n",
    "\n",
    "random_positive_tokens = random.sample(all_positive_test_tokens, 3)\n",
    "random_negative_tokens = random.sample(all_negative_test_tokens, 3)\n",
    "\n",
    "random_positive_token_values = {pos_token: averaged_token_values[pos_token] for pos_token in random_positive_tokens}\n",
    "random_negative_token_values = {neg_token: averaged_token_values[neg_token] for neg_token in random_negative_tokens}\n",
    "\n",
    "original_positive_values = {key: lexicon[key] for key in random_positive_tokens}\n",
    "original_negative_values = {key: lexicon[key] for key in random_negative_tokens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb844369-e9aa-47b0-acb3-448cb43f9018",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Reconstructed positive values: {random_positive_token_values}')\n",
    "print(f'Original positive values: {original_positive_values}')\n",
    "\n",
    "print(f'Reconstructed negative values: {random_negative_token_values}')\n",
    "print(f'Original negative values: {original_negative_values}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b838ef7d-fbc7-4bae-a4a9-187c0350e84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_dictionary_as_table(table_name: str, dictionary_values: dict, columns=[\"token\", \"value\"]):\n",
    "    all_values = []\n",
    "\n",
    "    for token, value in dictionary_values.items():\n",
    "        all_values.append({\"token\": token, \"value\": value})\n",
    "\n",
    "    final_df = pd.DataFrame(all_values)\n",
    "\n",
    "    print(final_df)\n",
    "\n",
    "    wandb.log({table_name: final_df})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832fe6dd-3715-4669-83b5-29cf6bba4a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dictionary_as_table(\n",
    "    \"sample_reconstructed_negative_token_utilities\", random_negative_token_values\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa53f931-4fd3-4fc4-ad57-43b0d89c49a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dictionary_as_table(\n",
    "    \"sample_reconstructed_positive_token_utilities\", random_positive_token_values\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd59708-4f5b-40aa-85a5-b81e51204a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dictionary_as_table(\n",
    "    \"full_reconstructed_token_utilities\", averaged_token_values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed666e04-9a80-4870-9935-7bfb7319ca4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_original_token_values = {token: lexicon[token] for token in averaged_token_values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046763e5-258c-4ef0-85b8-b0f5dc9ef7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dictionary_as_table(\n",
    "    \"original_vader_token_utilities\", full_original_token_values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffde7ec-5493-4832-b001-8ef966d54ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_ranking = sorted(\n",
    "    [(token, value) for token, value in averaged_token_values.items() if token in all_negative_test_tokens],\n",
    "    key = lambda x: x[1]\n",
    ")\n",
    "\n",
    "original_ranking = sorted(\n",
    "    [(token, lexicon[token]) for token in averaged_token_values if token in all_negative_test_tokens],\n",
    "    key = lambda x: x[1]\n",
    ")\n",
    "\n",
    "reconstructed_ranking_tokens_only = [item[0] for item in reconstructed_ranking]\n",
    "original_ranking_tokens_only = [item[0] for item in original_ranking]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5e04d8-74eb-473a-a694-d97a6b671779",
   "metadata": {},
   "outputs": [],
   "source": [
    "kendalltau(original_ranking_tokens_only, reconstructed_ranking_tokens_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0383040c-a975-4f46-9824-d21c7ba78339",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
