{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3633acd-cf3d-425e-b72f-5f677b50cce2",
   "metadata": {},
   "source": [
    "### Setup imports and environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f41234-47a8-4c19-84a7-106acbf9c899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff617388-7094-42b4-acda-ebc4f138e5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, Optional\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset, load_dataset\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    HfArgumentParser,\n",
    "    LlamaTokenizer,\n",
    "    pipeline\n",
    ")\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, HfArgumentParser, TrainingArguments\n",
    "from trl import AutoModelForCausalLMWithValueHead, DPOTrainer\n",
    "from trl import DPOTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9aa69b-50f6-48d8-9b0a-152a6546b58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f5183b-2cc9-4b3d-93be-1ea9db28235c",
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_hub_token = ###YOUR_TOKEN_HERE###\n",
    "wandb_api_key = ###YOUR_KEY_HERRE###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a074dba-931a-41d3-af9c-a137149d96dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['WANDB_API_KEY'] = wandb_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff7e823-2c66-4e0d-a92d-39855acf991d",
   "metadata": {},
   "source": [
    "### Setup Llama reward model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa40c75-30d0-47fa-ad2c-7fef28221be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_llama_reward_model():\n",
    "    rm_tokenizer = AutoTokenizer.from_pretrained(\"weqweasdas/hh_rlhf_rm_open_llama_3b\")\n",
    "    \n",
    "    rm_pipe = pipeline(\n",
    "        \"sentiment-analysis\",\n",
    "        model=\"weqweasdas/hh_rlhf_rm_open_llama_3b\",\n",
    "        device=\"cuda\",\n",
    "        tokenizer=rm_tokenizer,\n",
    "        model_kwargs={\"torch_dtype\": torch.bfloat16}\n",
    "    )\n",
    "    \n",
    "    pipe_kwargs = {\n",
    "        \"return_all_scores\": True,\n",
    "        \"function_to_apply\": \"none\",\n",
    "        \"batch_size\": 1\n",
    "    }\n",
    "    \n",
    "    test_texts = [\n",
    "        \"###Human: My daughter wants to know how to convert fractions to decimals, but I'm not sure how to explain it. Can you help? ###Assistant: Sure. So one way of converting fractions to decimals is to ask “how many halves are there?” and then write this as a decimal number. But that's a little tricky. Here's a simpler way:  if a fraction is expressed as a/b, then it's decimal equivalent is just a/b * 1.0  So, for example, the decimal equivalent of 1/2 is 1/2 * 1.0 = 0.5.\",\n",
    "        \"###Human: I have fresh whole chicken in my fridge. What dish can I prepare using it that will take me less than an hour to cook? ###Assistant: Are you interested in a quick and easy recipe you can prepare with chicken you have on hand, or something more involved?  In terms of both effort and time, what are you looking for?\",\n",
    "        \"###Human: My daughter wants to know how to convert fractions to decimals, but I'm not sure how to explain it. Can you help? ###Assistant: Yes, of course. Here you go.\"\n",
    "    ]\n",
    "    \n",
    "    pipe_outputs = rm_pipe(test_texts, **pipe_kwargs)\n",
    "    rewards = [output[0][\"score\"] for output in pipe_outputs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235eee04-f0b9-4754-8b38-568625e55eab",
   "metadata": {},
   "source": [
    "### Set up DPO arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3e2a0c-b9fb-4aab-b219-21679dfec0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, Optional\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset, load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, HfArgumentParser, TrainingArguments\n",
    "\n",
    "from trl import DPOTrainer\n",
    "\n",
    "\n",
    "# Define and parse arguments.\n",
    "@dataclass\n",
    "class ScriptArguments:\n",
    "    \"\"\"\n",
    "    The arguments for the DPO training script.\n",
    "    \"\"\"\n",
    "\n",
    "    # data parameters\n",
    "    beta: Optional[float] = field(default=0.1, metadata={\"help\": \"the beta parameter for DPO loss\"})\n",
    "\n",
    "    # training parameters\n",
    "    model_name_or_path: Optional[str] = field(default=\"EleutherAI/gpt-neo-125m\", metadata={\"help\": \"the model name\"})\n",
    "    learning_rate: Optional[float] = field(default=1.5e-4, metadata={\"help\": \"optimizer learning rate\"})\n",
    "    per_device_train_batch_size: Optional[int] = field(default=8, metadata={\"help\": \"batch size per device\"})\n",
    "    gradient_accumulation_steps: Optional[int] = field(\n",
    "        default=1, metadata={\"help\": \"the number of gradient accumulation steps\"}\n",
    "    )\n",
    "    max_length: Optional[int] = field(default=256, metadata={\"help\": \"max length of each sample\"})\n",
    "    max_prompt_length: Optional[int] = field(default=128, metadata={\"help\": \"max length of each sample's prompt\"})\n",
    "    max_target_length: Optional[int] = field(\n",
    "        default=128, metadata={\"help\": \"Only used for encoder decoder model. Max target of each sample's prompt\"}\n",
    "    )\n",
    "    label_pad_token_id: Optional[int] = field(default=-100, metadata={\"help\": \"label for non response tokens\"})\n",
    "    max_steps: Optional[int] = field(default=20050, metadata={\"help\": \"max number of training steps\"})\n",
    "\n",
    "    # instrumentation\n",
    "    sanity_check: Optional[bool] = field(default=False, metadata={\"help\": \"only train on 1000 samples\"})\n",
    "    report_to: Optional[str] = field(\n",
    "        default=\"wandb\",\n",
    "        metadata={\n",
    "            \"help\": 'The list of integrations to report the results and logs to. Supported platforms are `\"azure_ml\"`,'\n",
    "            '`\"comet_ml\"`, `\"mlflow\"`, `\"neptune\"`, `\"tensorboard\"`,`\"clearml\"` and `\"wandb\"`. '\n",
    "            'Use `\"all\"` to report to all integrations installed, `\"none\"` for no integrations.'\n",
    "        },\n",
    "    )\n",
    "    # debug argument for distributed training\n",
    "    ignore_bias_buffers: Optional[bool] = field(\n",
    "        default=False,\n",
    "        metadata={\n",
    "            \"help\": \"fix for DDP issues with LM bias/mask buffers - invalid scalar type,`inplace operation. See\"\n",
    "            \"https://github.com/huggingface/transformers/issues/22482#issuecomment-1595790992\"\n",
    "        },\n",
    "    )\n",
    "    gradient_checkpointing: Optional[bool] = field(\n",
    "        default=False, metadata={\"help\": \"Whether to use gradient checkpointing or no\"}\n",
    "    )\n",
    "    gradient_checkpointing_kwargs: Optional[dict] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"key word arguments to be passed along `torch.utils.checkpoint.checkpoint` method - e.g. `use_reentrant=False`\"\n",
    "        },\n",
    "    )\n",
    "\n",
    "    huggingface_hub_name: Optional[str] = field(\n",
    "        default='amirabdullah19852020/gpt-neo-125m_hh_reward', metadata={\"help\": \"Huggingface repo name\"}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400a4bf5-6aee-49e6-bf66-8bc7d620af7c",
   "metadata": {},
   "source": [
    "### Setup dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a45549-411f-445d-b493-d2c5b7915ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_anthropic_prompt(prompt_and_response):\n",
    "    \"\"\"Extract the anthropic prompt from a prompt and response pair.\"\"\"\n",
    "    search_term = \"\\n\\nAssistant:\"\n",
    "    search_term_idx = prompt_and_response.rfind(search_term)\n",
    "    assert search_term_idx != -1, f\"Prompt and response does not contain '{search_term}'\"\n",
    "    return prompt_and_response[: search_term_idx + len(search_term)]\n",
    "\n",
    "\n",
    "def get_hh(split: str = 'train', sanity_check: bool = False, silent: bool = False, cache_dir: str = None) -> Dataset:\n",
    "    \"\"\"Load the Anthropic Helpful-Harmless dataset from Hugging Face and convert it to the necessary format.\n",
    "\n",
    "    The dataset is converted to a dictionary with the following structure:\n",
    "    {\n",
    "        'prompt': List[str],\n",
    "        'chosen': List[str],\n",
    "        'rejected': List[str],\n",
    "    }\n",
    "\n",
    "    Prompts should be structured as follows:\n",
    "      \\n\\nHuman: <prompt>\\n\\nAssistant:\n",
    "    Multiple turns are allowed, but the prompt should always start with \\n\\nHuman: and end with \\n\\nAssistant:.\n",
    "    \"\"\"\n",
    "    dataset = load_dataset(\"Anthropic/hh-rlhf\", split=split, cache_dir=cache_dir)\n",
    "    if sanity_check:\n",
    "        dataset = dataset.select(range(min(len(dataset), 300)))\n",
    "\n",
    "    def split_prompt_and_responses(sample) -> Dict[str, str]:\n",
    "        prompt = extract_anthropic_prompt(sample[\"chosen\"])\n",
    "        return {\n",
    "            \"prompt\": prompt,\n",
    "            \"chosen\": sample[\"chosen\"][len(prompt) :],\n",
    "            \"rejected\": sample[\"rejected\"][len(prompt) :],\n",
    "        }\n",
    "\n",
    "    return dataset.map(split_prompt_and_responses)\n",
    "\n",
    "dataset = get_hh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1acce0-2578-46b9-97bd-4bee25d8298e",
   "metadata": {},
   "outputs": [],
   "source": [
    "script_args = ScriptArguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df529c1d-83b6-4a14-8ad7-401f16220e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(script_args.model_name_or_path).cuda()\n",
    "\n",
    "if script_args.ignore_bias_buffers:\n",
    "    # torch distributed hack\n",
    "    model._ddp_params_and_buffers_to_ignore = [\n",
    "        name for name, buffer in model.named_buffers() if buffer.dtype == torch.bool\n",
    "    ]\n",
    "\n",
    "model_ref = AutoModelForCausalLM.from_pretrained(script_args.model_name_or_path).cpu()\n",
    "tokenizer = AutoTokenizer.from_pretrained(script_args.model_name_or_path)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b172e9b7-e2fd-47c1-a034-3bb9f5d540bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = get_hh(\"train\", sanity_check=script_args.sanity_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64051cf-2f59-4279-b48e-c923cd6ca7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = get_hh(\"test\", sanity_check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9396b424-cd3a-4f00-9cb9-ace29aae125c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "        per_device_train_batch_size=script_args.per_device_train_batch_size,\n",
    "        max_steps=script_args.max_steps,\n",
    "        remove_unused_columns=False,\n",
    "        gradient_accumulation_steps=script_args.gradient_accumulation_steps,\n",
    "        learning_rate=script_args.learning_rate,\n",
    "        push_to_hub=True,\n",
    "        hub_model_id=script_args.huggingface_hub_name,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        logging_first_step=True,\n",
    "        logging_steps=10,\n",
    "        eval_steps=2000,\n",
    "        output_dir=\"./test\",\n",
    "        optim=\"adamw_hf\",\n",
    "        warmup_steps=150,\n",
    "        report_to=script_args.report_to,\n",
    "        bf16=True,\n",
    "        gradient_checkpointing=script_args.gradient_checkpointing\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce210d46-bad7-4011-a4a4-39b0c4af660a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpo_trainer = DPOTrainer(\n",
    "    model,\n",
    "    model_ref,\n",
    "    args=training_args,\n",
    "    beta=script_args.beta,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=script_args.max_length,\n",
    "    max_target_length=script_args.max_target_length,\n",
    "    max_prompt_length=script_args.max_prompt_length,\n",
    "    generate_during_eval=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf25a09-34f3-4914-8bb5-5534a5804e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e09f3ff-f1c2-4cfe-8b3e-fd27756b557e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpo_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc18c2e-1103-4f5b-8a58-95294be3e8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import huggingface_hub\n",
    "huggingface_hub.login(huggingface_hub_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4719efd4-a797-456f-843a-1a12a384450d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpo_trainer.push_to_hub()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
